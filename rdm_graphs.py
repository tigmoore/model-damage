"""
load damaged and healthy models, visualize activations in RDMs
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import registry
import torch.nn.utils.prune as prune
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

injury = []
for i in range(16):
    injury.append(1 - (1 - .2)**i)

# load csv files generated by prune_retrained_compressed.py
pruned = pd.read_csv('injured_model_paths/compressed_3/metrics/compressed_3_tau_pruned.csv', sep=',', header=None)

retrained = pd.read_csv('injured_model_paths/compressed_3/metrics/compressed_3_tau_retrained.csv', sep=',', header=None)

def plot_tau(x, y, y1, save=False):
    plt.plot(x, y, 'ro', label='pruned tau value')
    plt.plot(x, y1, 'g*', label='retrained tau value')
    plt.title('Kendalls Tau vs Injury: Model compressed to 5.42% of original')
    plt.legend(loc='center left')
    plt.xlabel('synaptic injury ratio')
    plt.ylabel('Kendalls tau')

    if save==True:
        plt.savefig('kendal_tao_comp_4')
    plt.show()


# plot_tau(injury, pruned, retrained)

# rdm figures
# a dict to store the activations
activation = {}

def getActivation(name):
  # the hook signature
  def hook(model, input, output):
    activation[name] = output.detach()
  return hook


def show_activation_layer_rdm(activation_layers, layer_name, figure_name):
    df = pd.DataFrame(activation_layers[layer_name])

    rdm = 1 - df.corr()
    f, ax = plt.subplots(figsize=(16, 18))
    plt.matshow(rdm, fignum=f.number)
    cb = plt.colorbar(fraction=0.046, pad=0.04)
    cb.ax.tick_params(labelsize=25)

    plt.title('Representational Dissimilarity Matrix', y=1.04, fontsize=40)
    plt.xlabel('Visual Stimuli', fontsize=40)
    plt.ylabel('Visual Stimuli', fontsize=40)
    plt.clim(0, 1)

    plt.tick_params(
        axis='both',  # changes apply to the both
        which='both',  # both major and minor ticks are affected
        bottom=False,  # ticks along the bottom edge are off
        top=False,  # ticks along the top edge are off
        right=False,
        left=False,
        labelbottom=False,
        labeltop=False,
        labelleft=False
        )
    ax.set_xticks([], [])
    ax.axis('off')
    figure_name = f'RDM_{figure_name}.png'
    plt.savefig(figure_name, dpi=300)
    plt.show()

    return rdm

# if using full model
full_path = 'run/cifar10/pretrain/cifar10_vgg19.pth'
full_inj_path = 'injured_model_paths/full_model/retrained_step_6.pth'
model = registry.get_model('vgg19', num_classes=10)
model.load_state_dict(torch.load(full_path))

#if using compressed models
comp_path =  'run/cifar10/prune/cifar10-global-l1-vgg19/cifar10_vgg19_l1_3.0.pth'
injured_path = 'injured_model_paths/compressed_3/prune_step_6.pth'
model_comp = torch.load(comp_path)


for name, module in model_comp.named_modules():
# iterively prune 0% of connections in all 2D-conv layers
    if isinstance(module, torch.nn.Conv2d):
        prune.random_unstructured(module, name='weight', amount=0)

    # iterively prune 0% of connections in all linear layers
    elif isinstance(module, torch.nn.Linear):
        prune.random_unstructured(module, name='weight', amount=0)

model_comp.load_state_dict(torch.load(injured_path))
model_comp = model_comp.to(device)

num_classes, train_dst, val_dst, input_size = registry.get_dataset('cifar10', data_root="data")

gt_class = [val_dst[i][1] for i in range(len(val_dst))]
lists = [[] for i in range(10)]


# sort indices of images into lists corresponding to same class
for i in range(len(gt_class)):
    for j in range(10):
        if gt_class[i] == j:
            lists[j].append(i)

model.pool2.register_forward_hook(getActivation('penultimate_layer'))
model.eval()

activation_layers_healthy = dict()
activation_layers_healthy[model.pool2] = {}
layer_name = model.pool2

for i in range(len(lists)):
    for j in range(100):
        # print(lists[i][j])
        img, label = val_dst[lists[i][j]]
        img = img.to(device)

        out = model(img.unsqueeze(0))

        get_layer_activation = activation['penultimate_layer']
        get_layer_activation = get_layer_activation.cpu()
        activ = np.asarray(get_layer_activation).squeeze()
        activation_layers_healthy[layer_name]['img_' + str(i) + str(j)] = activ.flatten()


# compressed model activations
model_comp.pool2.register_forward_hook(getActivation('penultimate_layer'))
model_comp.eval()

activation_layers_comp = dict()
layer_name_comp = model_comp.pool2
activation_layers_comp[layer_name_comp] = {}


for i in range(len(lists)):
    for j in range(100):
        # print(lists[i][j])
        img, label = val_dst[lists[i][j]]
        img = img.to(device)

        out = model_comp(img.unsqueeze(0))

        get_layer_activation = activation['penultimate_layer']
        get_layer_activation = get_layer_activation.cpu()
        activ = np.asarray(get_layer_activation).squeeze()
        activation_layers_comp[layer_name_comp]['img_' + str(i) + str(j)] = activ.flatten()


show_activation_layer_rdm(activation_layers_comp, layer_name_comp, 'comp_model_3_pruned_79')
show_activation_layer_rdm(activation_layers_healthy, layer_name, 'full_model_retrained_79')

